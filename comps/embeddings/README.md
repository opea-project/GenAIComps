# Embeddings Microservice

The Embedding Microservice is designed to efficiently convert textual strings into vectorized embeddings, facilitating seamless integration into various machine learning and data processing workflows. This service utilizes advanced algorithms to generate high-quality embeddings that capture the semantic essence of the input text, making it ideal for applications in natural language processing, information retrieval, and similar fields.

Key Features:

**High Performance**: Optimized for quick and reliable conversion of textual data into vector embeddings.

**Scalability**: Built to handle high volumes of requests simultaneously, ensuring robust performance even under heavy loads.

**Ease of Integration**: Provides a simple and intuitive API, allowing for straightforward integration into existing systems and workflows.

**Customizable**: Supports configuration and customization to meet specific use case requirements, including different embedding models and preprocessing techniques.

Users are albe to configure and build embedding-related services according to their actual needs.

## Embeddings Microservice with TEI

We support both `langchain` and `llama_index` for TEI serving.

For details, please refer to [langchain readme](tei/langchain/README.md) or [llama index readme](tei/llama_index/README.md).

## Embeddings Microservice with Mosec

For details, please refer to this [readme](mosec/langchain/README.md).

## Embeddings Microservice with Multimodal

For details, please refer to this [readme](multimodal/README.md).

## Embeddings Microservice with Multimodal Clip

For details, please refer to this [readme](multimodal_clip/README.md).

## Embeddings Microservice with Prediction Guard

For details, please refer to this [readme](predictionguard/README.md).
