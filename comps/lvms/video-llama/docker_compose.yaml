# Copyright (C) 2024 Intel Corporation
# SPDX-License-Identifier: Apache-2.0

version: "3"
services:
  lvm-video-llama:
    image: opea/video-llama-lvm-server:latest
    container_name: video-llama-lvm-server
    ports:
      - "9009:9009"
    ipc: host
    environment:
      http_proxy: ${http_proxy}
      https_proxy: ${https_proxy}
      no_proxy: ${no_proxy}
      llm_download: "False" # FIXME: prod True
    volumes:
      - "/home/$USER/.cache:/home/user/.cache" # RECOMMENDED: use cache to avoid download
      - "/home/raspadmin/tahani/GenAIExamples/VideoRAGQnA/meta-llama/Llama-2-7b-chat-hf:/home/user/model/Video-LLaMA-2-7B-Finetuned/llama-2-7b-chat-hf" # FIXME: dev use
      - "/home/raspadmin/tahani/GenAIExamples/VideoRAGQnA/embedding/video_llama_weights/VL_LLaMA_2_7B_Finetuned.pth:/home/user/model/Video-LLaMA-2-7B-Finetuned/VL_LLaMA_2_7B_Finetuned.pth" # FIXME: dev use
    restart: unless-stopped

  lvm:
    image: opea/lvm-video-llama:latest
    container_name: lvm-video-llama
    ports:
      - "9000:9000"
    ipc: host
    environment:
      http_proxy: ${http_proxy}
      https_proxy: ${https_proxy}
      no_proxy: ${no_proxy}
      LVM_ENDPOINT: ${LVM_ENDPOINT}
    # volumes:
    #   - "/home/$USER/.cache:/home/user/.cache"
    #   - "/home/raspadmin/tahani/GenAIExamples/VideoRAGQnA/meta-llama/Llama-2-7b-chat-hf:/home/user/model/Video-LLaMA-2-7B-Finetuned/llama-2-7b-chat-hf"
    #   - "/home/raspadmin/tahani/GenAIExamples/VideoRAGQnA/embedding/video_llama_weights/VL_LLaMA_2_7B_Finetuned.pth:/home/user/model/Video-LLaMA-2-7B-Finetuned/VL_LLaMA_2_7B_Finetuned.pth"
    restart: unless-stopped
    depends_on:
      - lvm-video-llama
  
networks:
  default:
    driver: bridge
volumes:
  my_models: