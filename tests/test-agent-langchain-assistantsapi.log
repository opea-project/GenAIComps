env_config:  ['--model', 'meta-llama/Meta-Llama-3.1-70B-Instruct', '--recursion_limit', '15', '--max_new_tokens', '4096', '--temperature', '0.01']
==========sys_args==========:
 Namespace(agent_name='OPEA_Default_Agent', custom_prompt=None, db_name=None, db_path=None, debug=False, hints_file=None, llm_endpoint_url='http://localhost:8080', llm_engine='tgi', max_new_tokens=4096, model='meta-llama/Meta-Llama-3.1-70B-Instruct', port=9090, recursion_limit=15, repetition_penalty=1.03, require_human_feedback=False, return_full_text=False, role_description='LLM enhanced agent', strategy='react_langchain', streaming=True, temperature=0.01, timeout=60, tools='tools/custom_tools.yaml', top_k=10, top_p=0.95, use_hints=False, with_memory=False, with_store=False)
test args: Namespace(agent_name='OPEA_Default_Agent', assistants_api_test=True, custom_prompt=None, db_name=None, db_path=None, debug=False, endpoint_test=False, ext_port='9095', filedir='./', filename='query.csv', hints_file=None, ip_addr='10.7.4.57', llm_endpoint_url='http://localhost:8080', llm_engine='tgi', local_test=False, max_new_tokens=4096, model='meta-llama/Meta-Llama-3.1-70B-Instruct', output='output.csv', port=9090, q=0, query='What is Intel OPEA project?', recursion_limit=15, repetition_penalty=1.03, require_human_feedback=False, return_full_text=False, role_description='LLM enhanced agent', strategy='react_langchain', streaming=True, temperature=0.01, timeout=60, tools='tools/custom_tools.yaml', top_k=10, top_p=0.95, use_hints=False, ut=False, with_memory=False, with_store=False)
send request to http://10.7.4.57:9095/v1/assistants, data is {}
{'id': 'assistant_ReActAgentwithLangchain_86106da1-87e8-4424-a4e4-6b2aa131d29a', 'object': 'assistant', 'created_at': 1733791024, 'name': None, 'description': None, 'model': 'Intel/neural-chat-7b-v3-3', 'instructions': None, 'tools': None}
Created Assistant Id:  assistant_ReActAgentwithLangchain_86106da1-87e8-4424-a4e4-6b2aa131d29a
send request to http://10.7.4.57:9095/v1/threads, data is {}
{'id': 'thread_2fa8fae7-6cfe-4b35-b2e0-eb214a80a81b', 'object': 'thread', 'created_at': 1733791024}
Created Thread Id:  thread_2fa8fae7-6cfe-4b35-b2e0-eb214a80a81b
send request to http://10.7.4.57:9095/v1/threads/thread_2fa8fae7-6cfe-4b35-b2e0-eb214a80a81b/messages, data is {"role": "user", "content": "What is Intel OPEA project?"}
{'id': 'msg_c7ab1fa5-30bb-45c8-950b-abdd4b0f9e1d', 'object': 'thread.message', 'created_at': 1733791024, 'thread_id': 'thread_2fa8fae7-6cfe-4b35-b2e0-eb214a80a81b', 'role': 'user', 'status': None, 'content': [{'type': 'text', 'text': 'What is Intel OPEA project?'}], 'assistant_id': None, 'run_id': None, 'attachments': None}
You may cancel the running process with cmdline
curl http://10.7.4.57:9095/v1/threads/thread_2fa8fae7-6cfe-4b35-b2e0-eb214a80a81b/runs/cancel -X POST -H 'Content-Type: application/json'
send request to http://10.7.4.57:9095/v1/threads/thread_2fa8fae7-6cfe-4b35-b2e0-eb214a80a81b/runs, data is {"assistant_id": "assistant_ReActAgentwithLangchain_86106da1-87e8-4424-a4e4-6b2aa131d29a"}
Calling Tool: `search_knowledge_base` with input `Intel OPEA project
`

Tool Result: `
    The Linux Foundation AI & Data announced the Open Platform for Enterprise AI (OPEA) as its latest Sandbox Project.
    OPEA aims to accelerate secure, cost-effective generative AI (GenAI) deployments for businesses by driving interoperability across a diverse and heterogeneous ecosystem, starting with retrieval-augmented generation (RAG).
    `

data: 'The Intel OPEA project, also known as the Open Platform for Enterprise AI, is a Linux Foundation AI & Data Sandbox Project that aims to accelerate secure and cost-effective generative AI deployments for businesses by driving interoperability across a diverse ecosystem, starting with retrieval-augmented generation (RAG).'

data: [DONE]

