global_envs:
  no_proxy: ${no_proxy}
  http_proxy: ${http_proxy}
  https_proxy: ${https_proxy}
  HUGGINGFACEHUB_API_TOKEN: ${HUGGINGFACEHUB_API_TOKEN}

micro_services:
  - service_name: redis-svc
    image: redis/redis-stack:7.2.0-v9
    ports:
      - "6379:6379"
      - "8001:8001"
  - service_name: dataprep-redis-svc
    image: opea/dataprep-redis:latest
    ports:
      - "6007:6007"
    envs:
      - REDIS_URL: ${REDIS_URL}
      - INDEX_NAME: ${INDEX_NAME}
      - TEI_ENDPOINT: ${TEI_EMBEDDING_ENDPOINT}
    dependencies:
      - redis-svc
  - service_name: embedding-svc
    image: ghcr.io/huggingface/tei-gaudi:latest
    ports:
      - "8090:80"
    volumes:
      - "./data:/data"
    replicas: 1
    resources:
      hpu: 1
    options:
      - runtime: habana
      - cap_add: SYS_NICE
    envs:
      - HABANA_VISIBLE_DEVICES: all
      - OMPI_MCA_btl_vader_single_copy_mechanism: none
      - MAX_WARMUP_SEQUENCE_LENGTH: 512
      - INIT_HCCL_ON_ACQUIRE: 0
      - ENABLE_EXPERIMENTAL_FLAGS: true
    args:
      - --model-id: ${EMBEDDING_MODEL_ID}
      - --auto-truncate
  - service_name: retriever-svc
    image: opea/retriever-redis:latest
    ports:
      - "7000:7000"
    envs:
      - REDIS_URL: ${REDIS_URL}
      - INDEX_NAME: ${INDEX_NAME}
      - TEI_EMBEDDING_ENDPOINT: ${TEI_EMBEDDING_ENDPOINT}
    dependencies:
      - redis-svc
  - service_name: raranking-tei-svc
    image: ghcr.io/huggingface/text-embeddings-inference:cpu-1.5
    ports:
      - "8808:80"
    volumes:
      - "./data:/data"
    replicas: 1
    resources:
      cpu: 48
      memory: 40G
    envs:
      HF_HUB_DISABLE_PROGRESS_BARS: 1
      HF_HUB_ENABLE_HF_TRANSFER: 0
    args:
      - --model-id BAAI/bge-reranker-base
      - --auto-truncate
  - service_name: tgi-svc
    image: ghcr.io/huggingface/tgi-gaudi:2.0.5
    ports:
      - "8005:80"
    volumes:
      - "./data:/data"
    replicas: 1
    resources:
      hpu: 1
    envs:
      - HF_HUB_DISABLE_PROGRESS_BARS: 1
      - HF_HUB_ENABLE_HF_TRANSFER: 0
      - HABANA_VISIBLE_DEVICES: all
      - OMPI_MCA_btl_vader_single_copy_mechanism: none
      - ENABLE_HPU_GRAPH: true
      - LIMIT_HPU_GRAPH: true
      - USE_FLASH_ATTENTION: true
      - FLASH_ATTENTION_RECOMPUTE: true
    options:
      - runtime: habana
      - cap_add: SYS_NICE
    args:
     - --model-id: Intel/neural-chat-7b-v3-3
     - --max-input-length: 2048
     - --max-total-tokens: 4096

mega_service:
  - service_name: chatqna_backend
    image: opea/chatqna:latest
    ports:
      - "8888:8888"
    envs:
      - MEGA_SERVICE_HOST_IP: ${MEGA_SERVICE_HOST_IP}
      - EMBEDDING_SERVICE_HOST_IP: ${EMBEDDING_SERVICE_HOST_IP}
      - EMBEDDING_SERVER_PORT: 8090
      - RETRIEVER_SERVICE_HOST_IP: ${RETRIEVER_SERVICE_HOST_IP}
      - RERANK_SERVICE_HOST_IP: ${RERANK_SERVICE_HOST_IP}
      - RERANK_SERVER_PORT: 8808
      - LLM_SERVICE_HOST_IP: ${LLM_SERVICE_HOST_IP}
      - LLM_SERVER_PORT: 8005
